{
    "ac_kwargs":	{
        "activation":	"ReLU",
        "hidden_sizes":	[
            400
        ]
    },
    "act_noise":	0.1,
    "actor_critic":	"MLPActorCritic",
    "batch_size":	100,
    "env_fn":	"functools.partial(functools.partial(<function env_fn at 0x7fda02cd5ea0>, env_name='gyroscopediscontinuousenv-v0', reward_type='Quadratic', reward_args={'qx1': 9, 'qx2': 0.05, 'qx3': 9, 'qx4': 0.05, 'pu1': 0.1, 'pu2': 0.1}), env_name='gyroscopediscontinuousenv-v0', reward_type='Normalized', reward_args={'k': 0.2})",
    "epochs":	100,
    "exp_name":	"Discontinuity and normalized reward function",
    "gamma":	0.995,
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x7fd9cb3ddf28>":	{
            "epoch_dict":	{},
            "exp_name":	"Discontinuity and normalized reward function",
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"ddpg_discontinuous_normalized",
            "output_file":	{
                "<_io.TextIOWrapper name='ddpg_discontinuous_normalized/progress.txt' mode='w' encoding='UTF-8'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{
        "exp_name":	"Discontinuity and normalized reward function",
        "output_dir":	"ddpg_discontinuous_normalized"
    },
    "max_ep_len":	110,
    "num_test_episodes":	10,
    "pi_lr":	0.001,
    "polyak":	0.995,
    "q_lr":	0.001,
    "replay_size":	1000000,
    "save_freq":	1,
    "seed":	0,
    "start_steps":	10000,
    "steps_per_epoch":	1650,
    "update_after":	1000,
    "update_every":	50
}
